import logging
import sys
import csv
import config as cfg
import constants as const
import xmltodict, json
import pandas as pd
import random
import uuid
import time

def get_logger(name, path):
    logger = logging.getLogger(name)
    logger.setLevel(logging.DEBUG)
    handler = logging.FileHandler(path, mode='w')
    handler.setLevel(logging.DEBUG)
    logger.addHandler(handler)
    return logger

class DBEmulator(process):
    def setup(config):
        self.conf = config['db_config']
        self.minLatency = config['minDBlatency']
        self.maxLatency = config['maxDBlatency']
        self.logger = get_logger('db_logger', config['db_log'])
        self.tables = {}

        with open(self.conf, 'r') as f:
            db_data = f.read()

        json_content = json.loads(json.dumps(xmltodict.parse(db_data)))['db']

        json_schema = json_content['schema']
        for schema in json_schema:
            self.tables[schema] = pd.DataFrame([], columns=json_schema[schema]['column'])

        json_data = json_content['data']

        for table in json_data:
            self.tables[table] = pd.read_json(json.dumps(json_data[table]))

    def run():
        print(self.tables)
        await(False)

    def _read(df, data):
        row = df[(df['id'] == data['id'])]
        if len(row) > 0:
            return row.iloc[0].to_json()
        else:
            new_data = []
            # print( list(df.cols))
            cols = df.columns

            for col in cols:
                for k in data:
                    df.ix[len(df), k] =  data[k]

            # df.loc[] = data
            return data

    def _write(df, data):
        index = df.loc[(df['id'] == data['id'])].index.tolist()
        if len(index) > 0:
            for k in data:
                df.ix[index[0], k] =  data[k]
        else:
            df.loc[len(df)] =  data

        return data

    def _op(fn, data):
        # should we use this flag or jus delay for every operation ?
        # should we delay the operation or literally mimic the visibility?
        # if later, we gotta think more about the design.. former is jus
        # removing the condition and jus delay for everything
        if data['delay']:
            time.sleep(random.randint(self.minLatency,self.maxLatency))

        payload = fn(self.tables[data['table']], data['payload'])
        print (self.tables[data['table']])

        return payload


    def receive(msg=('DB_READ', data), from_=p):
        self.logger.info('[DB_READ_REQ] payload:{}'.format(data))
        payload = self._op(self._read, data)
        send(('DB_READ_RESPONSE', payload),to=p)
        self.logger.info('[DB_READ_RESP] payload:{}'.format(data))

    def receive(msg=('DB_WRITE', data), from_=p):
        self.logger.info('[DB_WRITE_REQ] payload:{}'.format(data))
        payload = self._op(self._write, data)
        send(('DB_WRITE_RESPONSE', payload),to=p)
        self.logger.info('[DB_WRITE_RESP] payload:{}'.format(data))

# Client corresponds to Application instance
class Application(process):
    def setup(sub_coord_ps, config):
        self.logger = get_logger('app_logger', config['app_log'])
        # print(coord_ps)
        pass

    def get_sub_coord(sub):
        return list(sub_coord_ps)[0]

    def authorize(sub, res):
        app_id = str(uuid.uuid4())
        clk = logical_clock()
        payload = {
            'sub':sub,
            'res':res,
            'app_id':app_id,
            'req_no':clk
        }
        p = get_sub_coord(sub)
        
        send(('APP_EVALUATION_REQUEST',payload), to=p)
        self.logger.info('[SENT][APP_EVALUATION_REQUEST][{}] payload:{}'
                         .format(app_id, payload))

    def run():
        sub = {
            'type':'customer',
            'attr': {'count':2},
            'id':'1'
        }
        res = {
            'type':'movie',
            'attr': {'count':0},
            'id':'1'
        }
        authorize(sub, res)
        time.sleep(1)
        sub = {
            'type':'customer',
            'attr': {'count':1},
            'id':'1'
        }
        authorize(sub, res)
        time.sleep(1)
        sub = {
            'type':'customer',
            'attr': {'value':2,'count':3},
            'id':'1'
        }
        authorize(sub, res)
        await(False)

    def receive(msg=('APP_EVALUATION_RESPONSE', payload), from_=p):
        app_id = payload['app_id']
        self.logger.info('[RECEIVED][APP_EVALUATION_RESPONSE][{}] payload:{}'
                         .format(app_id, payload))



class SubCoordP(process):
    def setup(res_coord_ps, config):
        self.logger = get_logger('sub_coord_logger', config['sub_coord_log'])
        self.app_req_map = dict()
        columns = ['eval_id','sub','res', 'dep_eval_ids', 'status', 'req_no']
        self.eval_cache = pd.DataFrame([], columns=columns)

    def get_res_coord(res):
        return list(res_coord_ps)[0]

    def get_eval(eval_id, sub):
        row = self.eval_cache[(self.eval_cache['eval_id'] == eval_id)]
        if len(row) > 0:
            return json.loads(row.iloc[0].to_json())
        else:
            return None


    def run():
        await(False)

    def setup_cache(eval_id, sub, res, dep_eval_ids, req_no, status):
        data = {'eval_id': eval_id, 
                'sub': sub, 
                'res': res, 
                'dep_eval_ids': dep_eval_ids,
                'req_no': req_no, 
                'status':status}
        
        self.eval_cache.loc[len(self.eval_cache)] = data 

    def update_cache(eval_id):
        indices = self.eval_cache.loc[(self.eval_cache['eval_id'] == eval_id)].index.tolist()
        if indices:
            self.eval_cache.ix[indices[0], 'status'] = const.WORKER_COMPLETE

    def clear_cache(eval_id):
        del self.eval_cache[eval_id]
        del app_req_map[eval_id]

    def restart(eval_id):
        pass

    def add_tentative_attr_updates_to_req(sub, req_no):
        # TODO: use sub to find dependencies
        tentative_evals = get_tentative_evals(sub, req_no)
        for eval in tentative_evals:
            attrs = eval['sub']['attr']
            for k in attrs:
                if k in sub['attr']:
                    sub['attr'][k] = attrs[k]
        return sub, [eval['eval_id'] for eval in tentative_evals]

    def has_subject_attr_updates(eval_id):
        curr_eval = get_eval(eval_id, "sub_from_local_cache")
        sub_attrs = curr_eval['sub']['attr']
        # TODO: use sub to find dependencies
        tentative_evals = get_tentative_evals(curr_eval['sub'], curr_eval['req_no'])
        tentative_attrs = {}
        for eval in tentative_evals:
            for k in sub_attrs:
                if k in eval['sub']['attr']:
                    tentative_attrs[k] = sub_attrs[k]

        for k in tentative_attrs:
            if tentative_attrs[k] != sub_attrs[k]:
                return True

        return False


    def evaluate(app_id, sub, res, req_no, p):
        eval_id = str(uuid.uuid4())
        app_req_map[eval_id] = dict(app_id=app_id, sub=sub, res=res, req_no=req_no, app_p=p)
        sub, dependent_eval_ids = add_tentative_attr_updates_to_req(sub, req_no)
        setup_cache(eval_id, sub, res, dependent_eval_ids, req_no, const.PENDING)
        return eval_id, sub

    def get_tentative_evals(sub, req_no):
        evals = self.eval_cache[(self.eval_cache['status'] == const.WORKER_COMPLETE) & (self.eval_cache['req_no'] < req_no)]
        evals = evals.sort(['req_no'], ascending=[True])
        evals = json.loads(evals.to_json(orient="records"))
        eval_with_sub_attrs = []
        
        for eval in evals:
            for k in sub['attr']:
                if k in eval['sub']['attr']:
                    eval_with_sub_attrs.append(eval)
                    break

        return eval_with_sub_attrs

    def get_app(eval_id):
        return self.app_req_map[eval_id]['app_p']

    def process_worker_response(eval_id, result):
        if has_subject_attr_updates(eval_id):
            restart(eval_id)
        else:
            update_cache(eval_id)
            curr_eval = get_eval(eval_id, "sub_from_local_cache")
            # TODO: use sub to find dependencies
            tentative_evals = get_tentative_evals(curr_eval['sub'], curr_eval['req_no'])

            for eval in tentative_evals:
                # add await condition
                # Need to restart upon failure
                pass
        res = 'take res from cache'
        return res

    def process_res_commit_response(eval_id, result):
        return True

    def receive(msg= ('APP_EVALUATION_REQUEST', payload), from_=p):
        self.logger.info('[RECEIVED][APP_EVALUATION_REQUEST][{}] payload:{}'
                         .format(payload['app_id'], payload))

        res = payload['res']
        eval_id, sub = evaluate(payload['app_id'],
                                payload['sub'],
                                payload['res'],
                                payload['req_no'],
                                p)
        res_req_payload = dict(app_id=payload['app_id'],
                               eval_id=eval_id,
                               sub=sub,
                               res=res)

        send(('RES_EVALUATION_REQUEST', res_req_payload),to=get_res_coord(res))
        self.logger.info('[SENT][RES_EVALUATION_REQUEST][{}] payload:{}'
                         .format(res_req_payload['app_id'], res_req_payload))

    def receive(msg= ('WORKER_EVALUATION_RESPONSE', payload), from_=p):
        self.logger.info('[RECEIVED][WORKER_EVALUATION_RESPONSE][{}] payload:{}'
                         .format(payload['app_id'], payload))
        res = process_worker_response(payload['eval_id'], payload['result'])

        res_commit_payload = dict(eval_id=payload['eval_id'],
                                  app_id=payload['app_id'],
                                  res=res)
        send(('RES_COMMIT_REQUEST', res_commit_payload),to=get_res_coord(res))
        self.logger.info('[SENT][RES_COMMIT_REQUEST][{}] payload:{}'
                         .format(res_commit_payload['app_id'], res_commit_payload))


    def receive(msg= ('RES_COMMIT_RESPONSE', payload), from_=p):
        self.logger.info('[RECEIVED][RES_COMMIT_RESPONSE][{}] payload:{}'
                         .format(payload['app_id'], payload))
        result = process_res_commit_response(payload['eval_id'], payload['result'])
        if result:
            app_eval_payload = dict(result=payload['result'], app_id=payload['app_id'])
            send(('APP_EVALUATION_RESPONSE', app_eval_payload),to=get_app(payload['eval_id']))
            self.logger.info('[SENT][APP_EVALUATION_RESPONSE][{}] payload:{}'
                         .format(app_eval_payload['app_id'], app_eval_payload))
        else:
            # Restart myself
            pass


class ResCoordP(process):
    def setup(workers, config):
        self.logger = get_logger('res_coord_logger', config['res_coord_log'])
        self.eval_cache = dict()
        self.next_worker_idx = -1
        self.workers = list(workers)

    def run():
        await(False)

    # Select worker in a round robin fashion
    def get_worker():
        self.next_worker_idx += 1
        return self.workers[next_worker_idx%len(self.workers)]

    def get_eval(eval_id):
        return self.eval_cache.get(eval_id, None)

    def setup_cache(eval_id, sub, res):
        self.eval_cache[eval_id] = dict(sub=sub, res=res)

    def clear_cache(eval_id):
        del self.eval_cache[eval_id]

    def evaluate(eval_id, sub, res):
        if eval_id in self.eval_cache:
            clear_cache(eval_id)

        setup_cache(eval_id, sub, res)

    def conflict_exists(eval_id, res):
        eval = get_eval(eval_id)
        if not eval:
            return True

        for attr in self.eval['res']:
            if not (attr in res and res[attr] == self.eval['res'][attr]):
                return True

        return False


    def update_attr_db(eval_id, res):
        # TODO: Write the updates to db after constructing db
        eval = get_eval(eval_id)
        sub_id = eval['sub']['id']
        return

    def commit_evaluation(eval_id, res):
        if conflict_exists(eval_id, res):
            return True
        else:
            update_attr_db(eval_id, res)
            clear_cache(eval_id)
            return True

    def receive(msg= ('RES_EVALUATION_REQUEST', payload), from_=p):
        self.logger.info('[RECEIVED][RES_EVALUATION_REQUEST][{}] payload:{}'
                         .format(payload['app_id'], payload))
        evaluate(payload['eval_id'], payload['sub'], payload['res'])
        payload['sub_coord'] = p
        send(('WORKER_EVALUATION_REQUEST', payload),to=get_worker())

        self.logger.info('[SENT][WORKER_EVALUATION_REQUEST][{}] payload:{}'
                         .format(payload['app_id'], payload))

    def receive(msg= ('RES_COMMIT_REQUEST', payload), from_=p):
        self.logger.info('[RECEIVED][RES_COMMIT_REQUEST][{}] payload:{}'
                         .format(payload['app_id'], payload))

        result = commit_evaluation(payload['eval_id'], payload['res'])
        res_commit_payload = dict(eval_id=payload['eval_id'],
                                  result=result,
                                  app_id=payload['app_id'])

        send(('RES_COMMIT_RESPONSE', res_commit_payload),to=p)

        self.logger.info('[SENT][RES_COMMIT_RESPONSE][{}] payload:{}'
                             .format(res_commit_payload['app_id'], res_commit_payload))

class WorkerP(process):
    def setup(config):
        self.logger = get_logger('worker_logger', config['worker_log'])

    def evaluate(sub, res):
        return False

    def run():
        await(False)

    def receive(msg= ('WORKER_EVALUATION_REQUEST', payload), from_=p):
        self.logger.info('[RECEIVED][WORKER_EVALUATION_REQUEST][{}] payload:{}'
                         .format(payload['app_id'], payload))

        result = evaluate(payload['sub'], payload['res'])

        worker_resp_payload = dict(eval_id=payload['eval_id'],
                                   result=result,
                                   app_id=payload['app_id'])

        send(('WORKER_EVALUATION_RESPONSE', worker_resp_payload),to=payload['sub_coord'])

        self.logger.info('[SENT][WORKER_EVALUATION_RESPONSE][{}] payload:{}'
                         .format(worker_resp_payload['app_id'], worker_resp_payload))


def main():
    config_fpath = sys.argv[1] if len(sys.argv) > 1 else "../config/main-config.json"
    config = cfg.load_config(config_fpath)
    # do something with config
    config(channel="fifo", clock="Lamport")
    

    # db_ps = new(DBEmulator, num=1)
    # setup(db_ps,(config,))
    # start(db_ps)

    worker_ps = new(WorkerP, num=config['num_coords']*config['worker_count'])
    setup(worker_ps,(config,))
    start(worker_ps)

    res_coord_ps = new(ResCoordP, num=config['num_coords'])
    setup(res_coord_ps,(worker_ps, config,))
    start(res_coord_ps)

    sub_coord_ps = new(SubCoordP, num=config['num_coords'])
    setup(sub_coord_ps,(res_coord_ps, config,))
    start(sub_coord_ps)

    app_ps = new(Application, num=config['num_clients'])
    setup(app_ps,(sub_coord_ps, config,))
    start(app_ps)